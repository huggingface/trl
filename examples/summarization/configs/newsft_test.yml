output_dir: test
model_name_or_path: "EleutherAI/pythia-410m"
dataset_name: "CarperAI/openai_summarize_tldr"
dataset_train_name: train[:100]
dataset_test_name: valid[:100]
report_to: "wandb"
learning_rate: 1e-5
lr_scheduler_type: cosine
warmup_steps: 100
weight_decay: 0.05
fp16: True
bf16: False
gradient_checkpointing: False
gradient_accumulation_steps: 1
per_device_train_batch_size: 2
per_device_eval_batch_size: 8
num_train_epochs: 1
max_seq_length: 560
use_peft: True
lora_r: 8
lora_alpha: 32
logging_steps: 10
