model_name: /home/toolkit/huggingface/tldr_sft_pythia410m_fp32_trainall_3epochs
dataset_name: mnoukhov/openai_summarize_comparisons_relabel_pythia1b
beta: 0.5
num_train_epochs: 3
eval_steps: 750
load_in_8bit: False
bf16: False
fp16: True
learning_rate: 1e-5
use_peft: True
lora_all_linear: True
lora_r: 8
lora_alpha: 32
lora_dropout: 0.05
gradient_accumulation_steps: 4
per_device_train_batch_size: 4
warmup_steps: 150
eval_steps: 10
save_steps: 10
