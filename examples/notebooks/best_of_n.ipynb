{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQpNapZNWuXP"
   },
   "source": [
    "\n",
    "**Best-of-n sampling as an alternative to RLHF**\n",
    "\n",
    "This notebook compares reward-model scores of prompt based responses from \n",
    "1. a base model (`gpt2-imdb`)\n",
    "2. `RLHF` tuned model based on this base-model \n",
    "3. the base-model again from which we sample n responses to each prompt, score them and take the best scored one AKA the `best-of-n sampled` model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lo98lkdP66_x"
   },
   "source": [
    "Import dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vDA6qayz692w"
   },
   "outputs": [],
   "source": [
    "%pip install transformers trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "M1s_iNm773hM"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "from trl import AutoModelForCausalLMWithValueHead\n",
    "from trl.core import LengthSampler\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y7hyrIrO8tcY"
   },
   "source": [
    "Various constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MqS3OM6Q8x6g"
   },
   "outputs": [],
   "source": [
    "ref_model_name = \"lvwerra/gpt2-imdb\"\n",
    "model_name = \"lvwerra/gpt2-imdb-pos-v2\"\n",
    "reward_model = \"lvwerra/distilbert-imdb\"\n",
    "\n",
    "N_BEST_OF = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1YcXeElg6or"
   },
   "source": [
    "Models and  tokenizers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b855NrL181Hh"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(model_name)\n",
    "\n",
    "ref_model = AutoModelForCausalLMWithValueHead.from_pretrained(ref_model_name)\n",
    "\n",
    "reward_pipe = pipeline(\"sentiment-analysis\", model=reward_model, device=device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(ref_model_name)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# cuda-ize models\n",
    "model.cuda()\n",
    "ref_model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1Cz0gCFhZYJ"
   },
   "source": [
    "Dataset building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LqLVEp5p_8XM"
   },
   "outputs": [],
   "source": [
    "def build_dataset(tokenizer, dataset_name=\"stanfordnlp/imdb\", input_min_text_length=2, input_max_text_length=8):\n",
    "    # load imdb with datasets\n",
    "    ds = load_dataset(dataset_name, split=\"train\")\n",
    "    ds = ds.rename_columns({\"text\": \"review\"})\n",
    "    ds = ds.filter(lambda x: len(x[\"review\"]) > 200, batched=False)\n",
    "\n",
    "    input_size = LengthSampler(input_min_text_length, input_max_text_length)\n",
    "\n",
    "    def tokenize(sample):\n",
    "        sample[\"input_ids\"] = tokenizer.encode(sample[\"review\"])[: input_size()]\n",
    "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
    "        return sample\n",
    "\n",
    "    ds = ds.map(tokenize, batched=False)\n",
    "    ds.set_format(type=\"torch\")\n",
    "    return ds\n",
    "\n",
    "\n",
    "dataset = build_dataset(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "AqA2McjMAxNw"
   },
   "outputs": [],
   "source": [
    "gen_kwargs = {\"min_length\": -1, \"top_k\": 0.0, \"top_p\": 1.0, \"do_sample\": True, \"pad_token_id\": tokenizer.eos_token_id}\n",
    "sent_kwargs = {\"top_k\": None, \"function_to_apply\": \"none\", \"batch_size\": 16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "L_q4qs35AxcR"
   },
   "outputs": [],
   "source": [
    "output_min_length = 4\n",
    "output_max_length = 16\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
    "\n",
    "#### get a batch from the dataset\n",
    "bs = 16\n",
    "output_data = dict()\n",
    "dataset.set_format(\"pandas\")\n",
    "df_batch = dataset[:].sample(bs)\n",
    "output_data[\"query\"] = df_batch[\"query\"].tolist()\n",
    "query_tensors = df_batch[\"input_ids\"].tolist()\n",
    "\n",
    "# :: [Resp]\n",
    "response_tensors_ref, response_tensors = [], []\n",
    "# :: [[Resp]]\n",
    "response_tensors_best_of = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVfpyHnZBLKY"
   },
   "source": [
    "\n",
    "Generation using various models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-imZ7uEFBNbw"
   },
   "outputs": [],
   "source": [
    "for i in range(bs):\n",
    "    gen_len = output_length_sampler()\n",
    "\n",
    "    query = torch.tensor(query_tensors[i])\n",
    "\n",
    "    output = ref_model.generate(query.unsqueeze(dim=0).to(device), max_new_tokens=gen_len, **gen_kwargs).squeeze()\n",
    "    response_tensors_ref.append(tokenizer.decode(output))\n",
    "\n",
    "    output = model.generate(query.unsqueeze(dim=0).to(device), max_new_tokens=gen_len, **gen_kwargs).squeeze()\n",
    "    response_tensors.append(tokenizer.decode(output))\n",
    "\n",
    "    # generating copies of the same query for the Best-of-n sampling\n",
    "    queries = query.repeat((N_BEST_OF, 1))\n",
    "    output = ref_model.generate(queries.to(device), max_new_tokens=gen_len, **gen_kwargs).squeeze()\n",
    "    response_tensors_best_of.append(tokenizer.batch_decode(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jp5FC0Y5h_Sf"
   },
   "source": [
    "Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyDbbAQ0F_h7"
   },
   "outputs": [],
   "source": [
    "scores_ref = [output[0][\"score\"] for output in reward_pipe(response_tensors_ref, **sent_kwargs)]\n",
    "scores = [output[0][\"score\"] for output in reward_pipe(response_tensors, **sent_kwargs)]\n",
    "scores_best_of = []\n",
    "for i, response in enumerate(response_tensors_best_of):\n",
    "    # base_score = scores_ref[i]\n",
    "    scores_best_of.append(torch.tensor([output[0][\"score\"] for output in reward_pipe(response, **sent_kwargs)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 682
    },
    "id": "nA1GDNJEiGm-",
    "outputId": "1389c686-0751-4304-dea2-b71fd68748e1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "ref_model = AutoModelForCausalLMWithValueHead.from_pretrained(ref_model_name)\n",
       "\n",
       "reward_pipe = pipeline(\"sentiment-analysis\", model=reward_model, device=device)\n",
       "\n",
       "tokenizer = AutoTokenizer.from_pretrained(ref_model_name)\n",
       "\n",
       "tokenizer.pad_token = tokenizer.eos_token\n",
       "\n",
       "# cuda-ize models\n",
       "model.cuda()\n",
       "ref_model.cuda()"
      ],
      "metadata": {
       "id": "b855NrL181Hh"
      },
      "execution_count": null,
      "outputs": []
     },
     {
      "cell_type": "markdown",
      "source": [
       "Dataset building"
      ],
      "metadata": {
       "id": "Z1Cz0gCFhZYJ"
      }
     },
     {
      "cell_type": "code",
      "source": [
       "def build_dataset(tokenizer, dataset_name=\"stanfordnlp/imdb\", input_min_text_length=2, input_max_text_length=8):\n",
       "    # load imdb with datasets\n",
       "    ds = load_dataset(dataset_name, split=\"train\")\n",
       "    ds = ds.rename_columns({\"text\": \"review\"})\n",
       "    ds = ds.filter(lambda x: len(x[\"review\"]) > 200, batched=False)\n",
       "\n",
       "    input_size = LengthSampler(input_min_text_length, input_max_text_length)\n",
       "\n",
       "    def tokenize(sample):\n",
       "        sample[\"input_ids\"] = tokenizer.encode(sample[\"review\"])[: input_size()]\n",
       "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
       "        return sample\n",
       "\n",
       "    ds = ds.map(tokenize, batched=False)\n",
       "    ds.set_format(type=\"torch\")\n",
       "    return ds\n",
       "\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                 query  \\\n",
       "0                     I'm a pretty old   \n",
       "1                      One of the most   \n",
       "2                             Okay, as   \n",
       "3                        Watching \"Kro   \n",
       "4   Seriously what were they thinking?   \n",
       "5                         OK Hollywood   \n",
       "6                             \"Bend It   \n",
       "7   While the premise behind The House   \n",
       "8                       Well let me go   \n",
       "9                Vijay Krishna Acharya   \n",
       "10         Watching this movie made me   \n",
       "11                  There are probably   \n",
       "12                          Meryl Stre   \n",
       "13     I thought I read somewhere that   \n",
       "14                    Good movie, very   \n",
       "15                    It was agonizing   \n",
       "\n",
       "                                       response (ref)  scores (ref)  \\\n",
       "0       I'm a pretty old kid, well, with lots of girl      1.179652   \n",
       "1   One of the most psychologically devastating as...      2.477277   \n",
       "2   Okay, as ruthless as they are, even their leve...      1.466462   \n",
       "3                            Watching \"Kroger\" (1915-      0.186047   \n",
       "4   Seriously what were they thinking? It ain't go...      1.010697   \n",
       "5   OK Hollywood goes into a total game of audio, ...      0.934041   \n",
       "6   \"Bend It, Luther, Dodge, Church Goes to Rome w...      0.039218   \n",
       "7   While the premise behind The House of Dracula ...     -0.079306   \n",
       "8   Well let me go...I don't want to movie it. I'm...      1.015246   \n",
       "9    Vijay Krishna Acharya Sawai (Elverling). She was      0.341506   \n",
       "10  Watching this movie made me poorly appreciate ...      1.574047   \n",
       "11  There are probably more but if you had never s...     -0.047099   \n",
       "12                          Meryl Streep's version of      0.373884   \n",
       "13  I thought I read somewhere that the Lord had c...      0.091776   \n",
       "14  Good movie, very funny, acting is very good.<|...      2.408837   \n",
       "15            It was agonizing, and it made me wonder      1.240262   \n",
       "\n",
       "                                      response (RLHF)  scores (RLHF)  \\\n",
       "0   I'm a pretty old lady, and I loved this movie ...       2.218363   \n",
       "1      One of the most Antibiotic Apps I have seen in       2.145479   \n",
       "2   Okay, as I enjoyed the movie. It's added bonus...       2.239827   \n",
       "3                   Watching \"Kroven\". The film has a       1.044690   \n",
       "4   Seriously what were they thinking? It's a very...       2.753088   \n",
       "5   OK Hollywood shoot, and this is a classic. Som...       2.517364   \n",
       "6   \"Bend It all\" is a sophisticated, drawing and ...       2.583935   \n",
       "7   While the premise behind The House Intelligenc...       0.205217   \n",
       "8   Well let me go through everything says it's a ...       2.727040   \n",
       "9   Vijay Krishna Acharya is a perfect performance...       2.563642   \n",
       "10  Watching this movie made me sleep better. It w...       1.690222   \n",
       "11  There are probably random man only recently wh...       0.398258   \n",
       "12                              Meryl Streitz, who is       0.085154   \n",
       "13  I thought I read somewhere that my thoughts, a...       1.833734   \n",
       "14  Good movie, very much fuzz and logical based w...       2.325996   \n",
       "15       It was agonizing because it was truly fun to       0.969669   \n",
       "\n",
       "                                   response (best_of)  scores (best_of)  \n",
       "0   I'm a pretty old, stinking,acting kinda chick ...          2.016955  \n",
       "1   One of the most memorable performances of this...          2.676944  \n",
       "2   Okay, as I put it in such a negative mood, it ...          1.478424  \n",
       "3            Watching \"Kro\" is an entertainment craze          1.389495  \n",
       "4   Seriously what were they thinking? It was stil...          2.523514  \n",
       "5   OK Hollywood pay and the freaky set-up of this...          1.634765  \n",
       "6   \"Bend It 9\"/\"Zara Pephoto\") and an honest, rea...          2.557210  \n",
       "7   While the premise behind The House of Dracula ...          1.676889  \n",
       "8   Well let me go though, alive in this ever grow...          2.652859  \n",
       "9   Vijay Krishna Acharya adeptly emerges, and the...          2.308076  \n",
       "10  Watching this movie made me curious: what did ...          0.950836  \n",
       "11  There are probably too many documentaries in s...          1.142725  \n",
       "12                      Meryl Streep performed an awe          1.932498  \n",
       "13  I thought I read somewhere that The Odd Couple...          0.475951  \n",
       "14  Good movie, very well polished, nicely written...          2.820022  \n",
       "15           It was agonizing, poignant, and worst of          2.058277  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data[\"response (ref)\"] = response_tensors_ref\n",
    "output_data[\"scores (ref)\"] = scores_ref\n",
    "output_data[\"response (RLHF)\"] = response_tensors\n",
    "output_data[\"scores (RLHF)\"] = scores\n",
    "output_data[\"response (best_of)\"] = [\n",
    "    response_tensors_best_of[i][a.argmax().item()] for i, a in enumerate(scores_best_of)\n",
    "]\n",
    "output_data[\"scores (best_of)\"] = [a.max().item() for a in scores_best_of]\n",
    "\n",
    "\n",
    "# store results in a dataframe\n",
    "df_results = pd.DataFrame(output_data)\n",
    "df_results"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
