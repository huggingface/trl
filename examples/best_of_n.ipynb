{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import dependencies\n"
      ],
      "metadata": {
        "id": "Lo98lkdP66_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers trl "
      ],
      "metadata": {
        "id": "vDA6qayz692w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import pipeline, AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "\n",
        "from trl import AutoModelForCausalLMWithValueHead\n",
        "from trl.core import LengthSampler\n",
        "\n",
        "device = 0 if torch.cuda.is_available() else \"cpu\"  "
      ],
      "metadata": {
        "id": "M1s_iNm773hM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Various constants"
      ],
      "metadata": {
        "id": "Y7hyrIrO8tcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ref_model_name = 'lvwerra/gpt2-imdb'\n",
        "model_name     = 'lvwerra/gpt2-imdb-pos-v2'\n",
        "reward_model   = 'lvwerra/distilbert-imdb'\n",
        " \n",
        "N_BEST_OF      = 4"
      ],
      "metadata": {
        "id": "MqS3OM6Q8x6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Models and  tokenizers "
      ],
      "metadata": {
        "id": "c1YcXeElg6or"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLMWithValueHead.from_pretrained(model_name)\n",
        "\n",
        "ref_model = AutoModelForCausalLMWithValueHead.from_pretrained(ref_model_name)\n",
        "\n",
        "reward_pipe = pipeline(\"sentiment-analysis\", model=reward_model, device=device)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(ref_model_name)\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# cuda-ize models\n",
        "model.cuda()\n",
        "ref_model.cuda()"
      ],
      "metadata": {
        "id": "b855NrL181Hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset building"
      ],
      "metadata": {
        "id": "Z1Cz0gCFhZYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataset(tokenizer, dataset_name=\"imdb\", input_min_text_length=2, input_max_text_length=8):\n",
        "    \"\"\"\n",
        "    Build dataset for training. This builds the dataset from `load_dataset`, one should\n",
        "    customize this function to train the model on its own dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset_name (`str`):\n",
        "            The name of the dataset to be loaded.\n",
        "\n",
        "    Returns:\n",
        "        dataloader (`torch.utils.data.DataLoader`):\n",
        "            The dataloader for the dataset.\n",
        "    \"\"\"\n",
        "    # load imdb with datasets\n",
        "    ds = load_dataset(dataset_name, split=\"train\")\n",
        "    ds = ds.rename_columns({\"text\": \"review\"})\n",
        "    ds = ds.filter(lambda x: len(x[\"review\"]) > 200, batched=False)\n",
        "\n",
        "    input_size = LengthSampler(input_min_text_length, input_max_text_length)\n",
        "\n",
        "    def tokenize(sample):\n",
        "        sample[\"input_ids\"] = tokenizer.encode(sample[\"review\"])[: input_size()]\n",
        "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
        "        return sample\n",
        "\n",
        "    ds = ds.map(tokenize, batched=False)\n",
        "    ds.set_format(type=\"torch\")\n",
        "    return ds\n",
        "\n",
        "dataset = build_dataset(tokenizer)"
      ],
      "metadata": {
        "id": "LqLVEp5p_8XM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acd069a9-747c-4f6b-f816-e77bf132a6e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-b13b5100b4cec2ba.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-f7444e0781f3cbd5.arrow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_kwargs = {\"min_length\": -1, \"top_k\": 0.0, \"top_p\": 1.0, \"do_sample\": True, \"pad_token_id\": tokenizer.eos_token_id}\n",
        "sent_kwargs = {\"top_k\": None, \"function_to_apply\": \"none\", \"batch_size\": 16}"
      ],
      "metadata": {
        "id": "AqA2McjMAxNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "output_min_length = 4\n",
        "output_max_length = 16\n",
        "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
        "\n",
        "#### get a batch from the dataset\n",
        "bs = 16\n",
        "game_data = dict()\n",
        "dataset.set_format(\"pandas\")\n",
        "df_batch = dataset[:].sample(bs)\n",
        "game_data[\"query\"] = df_batch[\"query\"].tolist()\n",
        "query_tensors = df_batch[\"input_ids\"].tolist()\n",
        "\n",
        "# :: [Resp]\n",
        "response_tensors_ref, response_tensors = [], []\n",
        "# :: [[Resp]]\n",
        "response_tensors_best_of = []"
      ],
      "metadata": {
        "id": "L_q4qs35AxcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Generation using various models"
      ],
      "metadata": {
        "id": "QVfpyHnZBLKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(bs):\n",
        "    gen_len = output_length_sampler()\n",
        "\n",
        "    query = torch.tensor(query_tensors[i])\n",
        "\n",
        "    output = ref_model.generate(\n",
        "        query.unsqueeze(dim=0).to(device), max_new_tokens=gen_len, **gen_kwargs\n",
        "    ).squeeze()\n",
        "    response_tensors_ref.append(tokenizer.decode(output))\n",
        "\n",
        "    output = model.generate(\n",
        "        query.unsqueeze(dim=0).to(device), max_new_tokens=gen_len, **gen_kwargs\n",
        "    ).squeeze()\n",
        "    response_tensors.append(tokenizer.decode(output))\n",
        "    \n",
        "    # generating copies of the same query for the Best-of-n sampling\n",
        "    queries = query.repeat((N_BEST_OF,1))\n",
        "    output = model.generate(\n",
        "        queries.to(device), max_new_tokens=gen_len, **gen_kwargs\n",
        "    ).squeeze()\n",
        "    response_tensors_best_of.append(tokenizer.batch_decode(output))\n",
        "\n"
      ],
      "metadata": {
        "id": "-imZ7uEFBNbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scoring"
      ],
      "metadata": {
        "id": "Jp5FC0Y5h_Sf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores_ref = [output[0][\"score\"] for output in reward_pipe(response_tensors_ref, **sent_kwargs)]\n",
        "scores     = [output[0][\"score\"] for output in  reward_pipe(response_tensors, **sent_kwargs)]\n",
        "scores_best_of = []\n",
        "for i,response in enumerate(response_tensors_best_of):\n",
        "  base_score = scores_ref[i]\n",
        "  scores_best_of.append(torch.tensor([output[0][\"score\"] - base_score for output in reward_pipe(response, **sent_kwargs)]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyDbbAQ0F_h7",
        "outputId": "ad6fd697-46ba-4348-818e-c402eb2609ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/pipelines/base.py:1070: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "game_data[\"response (ref)\"] = response_tensors_ref\n",
        "game_data[\"scores (ref)\"] = scores_ref\n",
        "game_data[\"response (normal)\"] = response_tensors\n",
        "game_data[\"scores (normal)\"] = scores\n",
        "game_data[\"response (best_of)\"] = [response_tensors_best_of[i][a.argmax().item()] for i, a in enumerate(scores_best_of)]\n",
        "game_data[\"scores (best_of)\"] = [a.max().item() for a in scores_best_of]\n",
        "\n",
        "\n",
        "# store results in a dataframe\n",
        "df_results = pd.DataFrame(game_data)\n",
        "df_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "nA1GDNJEiGm-",
        "outputId": "50506392-7827-494c-c223-8e7972581f29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 query  \\\n",
              "0   First time of seeing Buster Keaton   \n",
              "1              So your bairns are away   \n",
              "2                  If Ashanti had been   \n",
              "3                           The funky,   \n",
              "4                          I first saw   \n",
              "5         I do not know if this movies   \n",
              "6                     The good news is   \n",
              "7            Salva and his pal Bigardo   \n",
              "8     The story would never win awards   \n",
              "9                     Oh, this is such   \n",
              "10                        I thoroughly   \n",
              "11      This is a lovely tale of guilt   \n",
              "12                     Yay!... I think   \n",
              "13         When I was in school I made   \n",
              "14                         This happy-   \n",
              "15    I consider myself a great admire   \n",
              "\n",
              "                                       response (ref)  scores (ref)  \\\n",
              "0   First time of seeing Buster Keaton again.<|end...      1.216213   \n",
              "1            So your bairns are away, this i think is      0.585517   \n",
              "2         If Ashanti had been moving fast to the next      0.191934   \n",
              "3   The funky, yummy-boy sound effects, mj3 energy...      1.382910   \n",
              "4          I first saw Girls From Hell tonight, but I      0.087289   \n",
              "5   I do not know if this movies corner will make ...      1.363110   \n",
              "6   The good news is that the old fighter pilots c...      0.331429   \n",
              "7   Salva and his pal Bigardo are killed before le...      0.104882   \n",
              "8   The story would never win awards at the Cannes...      1.339547   \n",
              "9   Oh, this is such a vice pic they should feel g...     -0.028055   \n",
              "10              I thoroughly enjoyed it.<|endoftext|>      2.643501   \n",
              "11  This is a lovely tale of guilt and forgive--bu...      2.451569   \n",
              "12  Yay!... I think you are SUPREMELY good at pict...      1.384551   \n",
              "13  When I was in school I made good by recording ...      1.782299   \n",
              "14  This happy-looking doctor arrives at the orpha...      0.939752   \n",
              "15  I consider myself a great admirer of Harry Ing...      2.164254   \n",
              "\n",
              "                                    response (normal)  scores (normal)  \\\n",
              "0   First time of seeing Buster Keaton's performan...         2.096043   \n",
              "1      So your bairns are away! A character like that         0.098930   \n",
              "2             If Ashanti had been a trained actor, he         0.076815   \n",
              "3   The funky, cerebral and honest story of our in...         2.652260   \n",
              "4   I first saw this movie years earlier. Everythi...         1.717765   \n",
              "5   I do not know if this movies will surprise me ...         2.845047   \n",
              "6   The good news is that BT's narration has been ...         1.910826   \n",
              "7    Salva and his pal Bigardo had a lot of potential         1.795311   \n",
              "8   The story would never win awards. It was a gre...         2.729562   \n",
              "9   Oh, this is such a good film. It has elements ...         2.646598   \n",
              "10  I thoroughly enjoyed this movie. It was so fun...         2.818993   \n",
              "11  This is a lovely tale of guilt and forgiveness...         2.848760   \n",
              "12      Yay!... I think it's great. It's just sort of         2.567049   \n",
              "13  When I was in school I made a movie about cert...         2.535886   \n",
              "14  This happy-and-surprising loading of delightfu...         2.878432   \n",
              "15  I consider myself a great admirer of the Nordi...         2.056158   \n",
              "\n",
              "                                   response (best_of)  scores (best_of)  \n",
              "0   First time of seeing Buster Keaton's movies, I...          1.370462  \n",
              "1             So your bairns are away, it's very capt          1.216446  \n",
              "2           If Ashanti had been miserable, and Mulder          1.627453  \n",
              "3   The funky, to put the bird in such as a deligh...          1.409587  \n",
              "4               I first saw this film in 2000, and it          1.616195  \n",
              "5   I do not know if this movies will inform my ow...          1.348881  \n",
              "6   The good news is they still have it all, just ...          1.917351  \n",
              "7   Salva and his pal Bigardo belong together in a...          2.389707  \n",
              "8   The story would never win awards, and I loved ...          1.578389  \n",
              "9   Oh, this is such a very good film. I like it even          2.836996  \n",
              "10  I thoroughly recommend this movie. It's a beau...          0.191151  \n",
              "11  This is a lovely tale of guilt and redemption....          0.460407  \n",
              "12  Yay!... I think it's a funny and totally touch...          1.331230  \n",
              "13  When I was in school I made fun of this movie,...          1.004798  \n",
              "14  This happy-happy conclusion to all these year....          1.860294  \n",
              "15  I consider myself a great admirer of past movi...          0.543658  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-26b66374-f288-4fa8-ab65-46e86f3f93c5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>response (ref)</th>\n",
              "      <th>scores (ref)</th>\n",
              "      <th>response (normal)</th>\n",
              "      <th>scores (normal)</th>\n",
              "      <th>response (best_of)</th>\n",
              "      <th>scores (best_of)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>First time of seeing Buster Keaton</td>\n",
              "      <td>First time of seeing Buster Keaton again.&lt;|end...</td>\n",
              "      <td>1.216213</td>\n",
              "      <td>First time of seeing Buster Keaton's performan...</td>\n",
              "      <td>2.096043</td>\n",
              "      <td>First time of seeing Buster Keaton's movies, I...</td>\n",
              "      <td>1.370462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>So your bairns are away</td>\n",
              "      <td>So your bairns are away, this i think is</td>\n",
              "      <td>0.585517</td>\n",
              "      <td>So your bairns are away! A character like that</td>\n",
              "      <td>0.098930</td>\n",
              "      <td>So your bairns are away, it's very capt</td>\n",
              "      <td>1.216446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>If Ashanti had been</td>\n",
              "      <td>If Ashanti had been moving fast to the next</td>\n",
              "      <td>0.191934</td>\n",
              "      <td>If Ashanti had been a trained actor, he</td>\n",
              "      <td>0.076815</td>\n",
              "      <td>If Ashanti had been miserable, and Mulder</td>\n",
              "      <td>1.627453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The funky,</td>\n",
              "      <td>The funky, yummy-boy sound effects, mj3 energy...</td>\n",
              "      <td>1.382910</td>\n",
              "      <td>The funky, cerebral and honest story of our in...</td>\n",
              "      <td>2.652260</td>\n",
              "      <td>The funky, to put the bird in such as a deligh...</td>\n",
              "      <td>1.409587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I first saw</td>\n",
              "      <td>I first saw Girls From Hell tonight, but I</td>\n",
              "      <td>0.087289</td>\n",
              "      <td>I first saw this movie years earlier. Everythi...</td>\n",
              "      <td>1.717765</td>\n",
              "      <td>I first saw this film in 2000, and it</td>\n",
              "      <td>1.616195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>I do not know if this movies</td>\n",
              "      <td>I do not know if this movies corner will make ...</td>\n",
              "      <td>1.363110</td>\n",
              "      <td>I do not know if this movies will surprise me ...</td>\n",
              "      <td>2.845047</td>\n",
              "      <td>I do not know if this movies will inform my ow...</td>\n",
              "      <td>1.348881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The good news is</td>\n",
              "      <td>The good news is that the old fighter pilots c...</td>\n",
              "      <td>0.331429</td>\n",
              "      <td>The good news is that BT's narration has been ...</td>\n",
              "      <td>1.910826</td>\n",
              "      <td>The good news is they still have it all, just ...</td>\n",
              "      <td>1.917351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Salva and his pal Bigardo</td>\n",
              "      <td>Salva and his pal Bigardo are killed before le...</td>\n",
              "      <td>0.104882</td>\n",
              "      <td>Salva and his pal Bigardo had a lot of potential</td>\n",
              "      <td>1.795311</td>\n",
              "      <td>Salva and his pal Bigardo belong together in a...</td>\n",
              "      <td>2.389707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>The story would never win awards</td>\n",
              "      <td>The story would never win awards at the Cannes...</td>\n",
              "      <td>1.339547</td>\n",
              "      <td>The story would never win awards. It was a gre...</td>\n",
              "      <td>2.729562</td>\n",
              "      <td>The story would never win awards, and I loved ...</td>\n",
              "      <td>1.578389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Oh, this is such</td>\n",
              "      <td>Oh, this is such a vice pic they should feel g...</td>\n",
              "      <td>-0.028055</td>\n",
              "      <td>Oh, this is such a good film. It has elements ...</td>\n",
              "      <td>2.646598</td>\n",
              "      <td>Oh, this is such a very good film. I like it even</td>\n",
              "      <td>2.836996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>I thoroughly</td>\n",
              "      <td>I thoroughly enjoyed it.&lt;|endoftext|&gt;</td>\n",
              "      <td>2.643501</td>\n",
              "      <td>I thoroughly enjoyed this movie. It was so fun...</td>\n",
              "      <td>2.818993</td>\n",
              "      <td>I thoroughly recommend this movie. It's a beau...</td>\n",
              "      <td>0.191151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>This is a lovely tale of guilt</td>\n",
              "      <td>This is a lovely tale of guilt and forgive--bu...</td>\n",
              "      <td>2.451569</td>\n",
              "      <td>This is a lovely tale of guilt and forgiveness...</td>\n",
              "      <td>2.848760</td>\n",
              "      <td>This is a lovely tale of guilt and redemption....</td>\n",
              "      <td>0.460407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Yay!... I think</td>\n",
              "      <td>Yay!... I think you are SUPREMELY good at pict...</td>\n",
              "      <td>1.384551</td>\n",
              "      <td>Yay!... I think it's great. It's just sort of</td>\n",
              "      <td>2.567049</td>\n",
              "      <td>Yay!... I think it's a funny and totally touch...</td>\n",
              "      <td>1.331230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>When I was in school I made</td>\n",
              "      <td>When I was in school I made good by recording ...</td>\n",
              "      <td>1.782299</td>\n",
              "      <td>When I was in school I made a movie about cert...</td>\n",
              "      <td>2.535886</td>\n",
              "      <td>When I was in school I made fun of this movie,...</td>\n",
              "      <td>1.004798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>This happy-</td>\n",
              "      <td>This happy-looking doctor arrives at the orpha...</td>\n",
              "      <td>0.939752</td>\n",
              "      <td>This happy-and-surprising loading of delightfu...</td>\n",
              "      <td>2.878432</td>\n",
              "      <td>This happy-happy conclusion to all these year....</td>\n",
              "      <td>1.860294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>I consider myself a great admire</td>\n",
              "      <td>I consider myself a great admirer of Harry Ing...</td>\n",
              "      <td>2.164254</td>\n",
              "      <td>I consider myself a great admirer of the Nordi...</td>\n",
              "      <td>2.056158</td>\n",
              "      <td>I consider myself a great admirer of past movi...</td>\n",
              "      <td>0.543658</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-26b66374-f288-4fa8-ab65-46e86f3f93c5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-26b66374-f288-4fa8-ab65-46e86f3f93c5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-26b66374-f288-4fa8-ab65-46e86f3f93c5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}