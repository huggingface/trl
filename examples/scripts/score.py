# [WIP]
from dataclasses import dataclass, field
from typing import Optional

import torch
from accelerate import Accelerator
from datasets import load_from_disk
from torch.utils.data import DataLoader
from transformers import (
    AutoModelForSequenceClassification,
    AutoTokenizer,
    DataCollatorWithPadding,
    HfArgumentParser
)
from tqdm import tqdm


@dataclass
class ScriptArguments:
    reward_model_name_or_path: Optional[str] = field(default=None, metadata={"help": "the reward model name"})
    
    dataset_name: Optional[str] = field(default=None, metadata={"help": "the HF data path"})
    save_dataset_path: Optional[str] = field(default=None, metadata={"help": "the HF data path"})
    generation_column_name: Optional[str] = field(default="generated")
    
    eval_bs: Optional[int] = field(default=16, metadata={"help": "the reward model batch size"})
    max_length: Optional[int] = field(default=512, metadata={"help": "the maximum length"})
    sanity_check: Optional[bool] = field(default=False)
    
    bf16: Optional[bool] = field(default=True if torch.cuda.get_device_capability()[0] == 8 else False, metadata={"help": "whether to use bf16."})
    fp16: Optional[bool] = field(default=True if not torch.cuda.get_device_capability()[0] == 8 else False, metadata={"help": "whether to use fp16."})


def score(script_args, reward_dataset = None):
    
    accelerator = Accelerator(
        mixed_precision= "bf16" if script_args.bf16 else "fp16" if script_args.fp16 else "no"
    )

    # Load model, reward model and tokenizer
    reward_model = AutoModelForSequenceClassification.from_pretrained(script_args.reward_model_name_or_path)
    reward_model.eval()
    tokenizer = AutoTokenizer.from_pretrained(script_args.reward_model_name_or_path)
    
    # make sure not to truncate the response generated by the model
    tokenizer.truncation_side = "left"
    if tokenizer.pad_token_id is None:
        tokenizer.pad_token_id = tokenizer.eos_token_id

    if reward_dataset is None:
        reward_dataset = load_from_disk(script_args.dataset_name)
    
    if script_args.sanity_check:
        dataset = dataset.select(range(min(len(reward_dataset), 500)))


    def preprocess_function(sample):
        model_inputs = tokenizer(sample["generated"], max_length=script_args.max_length, truncation=True)
        return model_inputs

    reward_dataset = reward_dataset.map(preprocess_function, batched=True, remove_columns=list(reward_dataset.features))

    reward_collator = DataCollatorWithPadding(tokenizer, padding=True, max_length=script_args.max_length)
    reward_dataloader = DataLoader(reward_dataset, batch_size=script_args.eval_bs, shuffle=False, collate_fn=reward_collator)
    
    reward_model, reward_dataloader = accelerator.prepare(reward_model,reward_dataloader)

    accelerator.wait_for_everyone()

    all_rewards = []
    pbar = tqdm(total=len(reward_dataloader), disable=not accelerator.is_local_main_process)
    
    for batch in reward_dataloader:
        with torch.no_grad():
            rewards = reward_model(**batch).logits
            rewards = accelerator.gather(rewards)
            all_rewards.extend(rewards)
            pbar.update(1)

    accelerator.wait_for_everyone()
    
    all_rewards = [reward.item() for reward in all_rewards][: len(reward_dataset)]
    
    reward_dataset = reward_dataset.add_column("rewards", all_rewards)
    
    def postprocess_function(sample):
        original_sentences = tokenizer.batch_decode(sample["input_ids"], skip_special_tokens=True)

        data = {
            "text":original_sentences,
            "rewards":sample["rewards"]
        }
        return data
    
    reward_dataset = reward_dataset.map(postprocess_function, batched=True, remove_columns=list(reward_dataset.features))
    
    if accelerator.is_local_main_process:
        reward_dataset.save_to_disk(script_args.save_dataset_path)
    
    return reward_dataset
    
def main():
    
    parser = HfArgumentParser(ScriptArguments)
    script_args = parser.parse_args_into_dataclasses()[0]
    score(script_args)

if __name__ == "__main__":
    main()
