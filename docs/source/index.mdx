<div style="text-align: center">
<img src="https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/images/trl_banner_dark.png">
</div>

# TRL - Transformer Reinforcement Learning

TRL is a full stack library where we provide a set of tools to train transformer language models with Reinforcement Learning, from the Supervised Fine-tuning step (SFT), Reward Modeling step (RM) to the Proximal Policy Optimization (PPO) step. 
The library is integrated with ðŸ¤— [transformers](https://github.com/huggingface/transformers).

<div style="text-align: center">
<img src="https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/images/TRL-readme.png">
</div>

Check the appropriate sections of the documentation depending on your needs:

API documentation:

- [Model Classes](models)
- [`SFTTrainer`](sft_trainer)
- [`RewardTrainer`](reward_trainer)
- [`PPOTrainer`](trainer)
- [Best-of-N Samppling](best-of-n)


Examples: 

- [Sentiment Tuning](sentiment_tuning)
- [Training with PEFT](lora_tuning_peft)
- [Detoxifying LLMs](detoxifying_a_lm)
- [StackLlama](using_llama_models)
- [Multi-Adapter Training](multi_adapter_rl)
