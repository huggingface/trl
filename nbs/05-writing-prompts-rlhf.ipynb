{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YzUa8EUOcwW"
      },
      "source": [
        "# Tune a language model to generate responses to writing prompts\n",
        "> Optimise a language model to produce responses to reddit writing prompts using a dataset of writing prompt response comparisons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SksLXMnFOcwZ"
      },
      "source": [
        "## Setup experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XesXYwlZOcwa"
      },
      "source": [
        "### Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install accelerate\n",
        "!pip install sentencepiece\n",
        "!pip install huggingface_hub\n",
        "!apt install git-lfs\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "cd76ed84e13f4f1196a4c49fc92505ce",
            "ddb8794cae0d4d57ba70ee94ad8b2e69",
            "6994bd4bfc4d4225a146e03bd9636912",
            "a38c9d3580f6483cb8c1511a50cda803",
            "68046152fe0d45fe86b5155aaac59a5e",
            "4f585770b6c44dafb61676cf62d6e067",
            "ed719c66f4c140b5889a07d045b66e19",
            "db8854d65a0b409d930ea4f3742005ba",
            "9bfd7482e525464783234f1899a85b71",
            "b848bc78623a4fde999de5ce192cc9ea",
            "3d79cfe9ad2b45909d7cfc9bf1a3ff4a",
            "55d2ab452e6e4d3ab78fad0cf7e5317b",
            "29f51c36ad534125b9121f4cd48f724e",
            "1155bee42134434a93ea29b88e1f353d",
            "ef55295181734966a3771b075b21153a",
            "9a82c8ab3da9488e9e2376ed7f7c6c76",
            "750469af67ff4c43b5a4f8565a4715dd"
          ]
        },
        "id": "b3_FsD6uE8sl",
        "outputId": "c23566b2-9a83-45f2-c0a7-f1612c9c86b3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Login successful\n",
            "Your token has been saved to /root/.huggingface/token\n",
            "\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n",
            "\n",
            "git config --global credential.helper store\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "N34o7e3_Ocwc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import wandb\n",
        "import time\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "import torch\n",
        "import collections\n",
        "import time\n",
        "import random\n",
        "tqdm.pandas()\n",
        "\n",
        "from datasets import load_dataset, ClassLabel, load_metric, concatenate_datasets\n",
        "\n",
        "from transformers import AutoConfig, AutoModel, AutoTokenizer, AutoModelForPreTraining\n",
        "from transformers import top_k_top_p_filtering\n",
        "from torch import nn\n",
        "from torch.nn import Identity\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "from transformers import GPT2Tokenizer\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding, AdamW, get_scheduler, AutoModelForCausalLM, GPT2PreTrainedModel\n",
        "\n",
        "from accelerate import Accelerator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions and Classes"
      ],
      "metadata": {
        "id": "yBjSQMWJBcwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten_dict(nested, sep='/'):\n",
        "    \"\"\"Flatten dictionary and concatenate nested keys with separator.\"\"\"\n",
        "    def rec(nest, prefix, into):\n",
        "        for k, v in nest.items():\n",
        "            if sep in k:\n",
        "                raise ValueError(f\"separator '{sep}' not allowed to be in key '{k}'\")\n",
        "            if isinstance(v, collections.Mapping):\n",
        "                rec(v, prefix + k + sep, into)\n",
        "            else:\n",
        "                into[prefix + k] = v\n",
        "    flat = {}\n",
        "    rec(nested, '', flat)\n",
        "    return flat\n",
        "\n",
        "def stack_dicts(stats_dicts):\n",
        "    \"\"\"Stack the values of a dict.\"\"\"\n",
        "    results = dict()\n",
        "    for k in stats_dicts[0]:\n",
        "        stats_list = [torch.flatten(d[k]) for d in stats_dicts]\n",
        "        results[k] = torch.stack(stats_list)\n",
        "    return results\n",
        "\n",
        "def add_suffix(input_dict, suffix):\n",
        "    \"\"\"Add suffix to dict keys.\"\"\"\n",
        "    return dict((k + suffix, v) for k,v in input_dict.items())\n",
        "\n",
        "# Cell\n",
        "\n",
        "def pad_to_size(tensor, size, dim=1, padding=50256):\n",
        "    \"\"\"Pad tensor to size.\"\"\"\n",
        "    t_size = tensor.size()[dim]\n",
        "    if t_size==size:\n",
        "        return tensor\n",
        "    else:\n",
        "        return torch.nn.functional.pad(tensor, (0,size-t_size), 'constant', padding)\n",
        "\n",
        "def logprobs_from_logits(logits, labels):\n",
        "    \"\"\"\n",
        "    See: https://github.com/pytorch/pytorch/issues/563#issuecomment-330103591\n",
        "    \"\"\"\n",
        "    logp = F.log_softmax(logits, dim=2)\n",
        "    logpy = torch.gather(logp, 2, labels.unsqueeze(2)).squeeze(-1)\n",
        "    return logpy\n",
        "\n",
        "\n",
        "def whiten(values, shift_mean=True):\n",
        "    \"\"\"Whiten values.\"\"\"\n",
        "    mean, var = torch.mean(values), torch.var(values)\n",
        "    whitened = (values - mean) * torch.rsqrt(var + 1e-8)\n",
        "    if not shift_mean:\n",
        "        whitened += mean\n",
        "    return whitened\n",
        "\n",
        "def clip_by_value(x, tensor_min, tensor_max):\n",
        "    \"\"\"\n",
        "    Tensor extenstion to torch.clamp\n",
        "    https://github.com/pytorch/pytorch/issues/2793#issuecomment-428784713\n",
        "    \"\"\"\n",
        "    clipped = torch.max(torch.min(x, tensor_max), tensor_min)\n",
        "    return clipped\n",
        "\n",
        "def entropy_from_logits(logits):\n",
        "    \"\"\"Calculate entropy from logits.\"\"\"\n",
        "    pd = torch.nn.functional.softmax(logits, dim=-1)\n",
        "    entropy = torch.logsumexp(logits, axis=-1) - torch.sum(pd*logits, axis=-1)\n",
        "    return entropy\n",
        "\n",
        "\n",
        "def average_torch_dicts(list_of_dicts):\n",
        "    \"\"\"Average values of a list of dicts wiht torch tensors.\"\"\"\n",
        "    average_dict = dict()\n",
        "    for key in list_of_dicts[0].keys():\n",
        "        average_dict[key] = torch.mean(torch.stack([d[key] for d in list_of_dicts]), axis=0)\n",
        "    return average_dict\n",
        "\n",
        "def stats_to_np(stats_dict):\n",
        "    \"\"\"Cast all torch.tensors in dict to numpy arrays.\"\"\"\n",
        "    new_dict = dict()\n",
        "    for k, v in stats_dict.items():\n",
        "        if isinstance(v, torch.Tensor):\n",
        "            new_dict[k] = v.detach().cpu().numpy()\n",
        "        else:\n",
        "            new_dict[k] = v\n",
        "        if np.isscalar(new_dict[k]):\n",
        "            new_dict[k] = float(new_dict[k])\n",
        "    return new_dict"
      ],
      "metadata": {
        "id": "CtaLOJeEYq6H"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ValueHead(nn.Module):\n",
        "    \"\"\"The ValueHead class implements a head for a language model that returns a scalar for each output token.\"\"\"\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.summary_type = config.summary_type if hasattr(config, \"summary_type\") else \"last\"\n",
        "        if self.summary_type == \"attn\":\n",
        "            raise NotImplementedError\n",
        "\n",
        "        self.summary = Identity()\n",
        "        if hasattr(config, \"summary_use_proj\") and config.summary_use_proj:\n",
        "            if hasattr(config, \"summary_proj_to_labels\") and config.summary_proj_to_labels and config.num_labels > 0:\n",
        "                num_classes = config.num_labels\n",
        "            else:\n",
        "                num_classes = config.hidden_size\n",
        "            self.summary = nn.Linear(config.hidden_size, num_classes)\n",
        "\n",
        "        self.activation = Identity()\n",
        "        if hasattr(config, \"summary_activation\") and config.summary_activation == \"tanh\":\n",
        "            self.activation = nn.Tanh()\n",
        "\n",
        "        self.first_dropout = Identity()\n",
        "        if hasattr(config, \"summary_first_dropout\") and config.summary_first_dropout > 0:\n",
        "            self.first_dropout = nn.Dropout(config.summary_first_dropout)\n",
        "\n",
        "        self.last_dropout = Identity()\n",
        "        if hasattr(config, \"summary_last_dropout\") and config.summary_last_dropout > 0:\n",
        "            self.last_dropout = nn.Dropout(config.summary_last_dropout)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "    def forward(self, hidden_states, cls_index=None):\n",
        "        output = hidden_states\n",
        "        output = self.first_dropout(output)\n",
        "        output = self.summary(output)\n",
        "        output = self.activation(output)\n",
        "        output = self.last_dropout(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "# Cell\n",
        "\n",
        "class LMHeadWithValueModel(GPT2PreTrainedModel):\n",
        "    \"\"\"The LMHeadWithValueModel class implements a language model with a secondary, scalar head.\"\"\"\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        config.num_labels = 1\n",
        "        self.transformer = AutoModel.from_config(config)\n",
        "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "        self.v_head = ValueHead(config)\n",
        "\n",
        "        self.init_weights()\n",
        "    \n",
        "    def get_output_embeddings(self):\n",
        "        return self.lm_head\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        past_key_values=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        mc_token_ids=None,\n",
        "        lm_labels=None,\n",
        "        mc_labels=None,\n",
        "    ):\n",
        "       \n",
        "        transformer_outputs = self.transformer(\n",
        "            input_ids,\n",
        "            past_key_values=past_key_values,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "        )\n",
        "\n",
        "        hidden_states = transformer_outputs[0]\n",
        "\n",
        "        lm_logits = self.lm_head(hidden_states)\n",
        "        value = self.v_head(hidden_states).squeeze(-1)\n",
        "\n",
        "        outputs = (lm_logits,) + transformer_outputs[1:] + (value,)\n",
        "        \n",
        "        return outputs\n",
        "\n",
        "# Cell\n",
        "\n",
        "def respond_to_batch(model, queries, txt_len=20, top_k=0, top_p=1.0):\n",
        "    \"\"\"Sample text from language model.\"\"\"\n",
        "    input_ids = queries\n",
        "    for i in range(txt_len):\n",
        "        # Get Logits\n",
        "        outputs = model(input_ids)\n",
        "        next_token_logits = outputs[0][:, -1, :]\n",
        "        next_token_logits = top_k_top_p_filtering(next_token_logits, top_k=top_k, top_p=top_p)\n",
        "        # Sample\n",
        "        probs = F.softmax(next_token_logits, dim=-1)\n",
        "        next_token = torch.multinomial(probs, num_samples=1).squeeze(1)\n",
        "        input_ids = torch.cat([input_ids, next_token.unsqueeze(-1)], dim=-1)\n",
        "    return input_ids[:, -txt_len:]"
      ],
      "metadata": {
        "id": "LhLUVZIGYtXM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaptiveKLController:\n",
        "    \"\"\"\n",
        "    Adaptive KL controller described in the paper:\n",
        "    https://arxiv.org/pdf/1909.08593.pdf\n",
        "    \"\"\"\n",
        "    def __init__(self, init_kl_coef, target, horizon):\n",
        "        self.value = init_kl_coef\n",
        "        self.target = target\n",
        "        self.horizon = horizon\n",
        "\n",
        "    def update(self, current, n_steps):\n",
        "        target = self.target\n",
        "        proportional_error = np.clip(current / target - 1, -0.2, 0.2)\n",
        "        mult = 1 + proportional_error * n_steps / self.horizon\n",
        "        self.value *= mult\n",
        "\n",
        "# Cell\n",
        "\n",
        "class FixedKLController:\n",
        "    \"\"\"Fixed KL controller.\"\"\"\n",
        "    def __init__(self, kl_coef):\n",
        "        self.value = kl_coef\n",
        "\n",
        "    def update(self, current, n_steps):\n",
        "        pass\n",
        "\n",
        "# Cell\n",
        "\n",
        "class PPOTrainer:\n",
        "    \"\"\"\n",
        "    The PPO_trainer uses Proximal Policy Optimization to optimise language models.\n",
        "    \"\"\"\n",
        "\n",
        "    default_params = {\n",
        "        \"lr\": 1.41e-5,\n",
        "        \"adap_kl_ctrl\": True,\n",
        "        \"init_kl_coef\":0.2,\n",
        "        \"target\": 6,\n",
        "        \"horizon\":10000,\n",
        "        \"gamma\":1,\n",
        "        \"lam\":0.95,\n",
        "        \"cliprange\": .2,\n",
        "        \"cliprange_value\":.2,\n",
        "        \"vf_coef\":.1,\n",
        "        \"batch_size\": 256,\n",
        "        \"forward_batch_size\": 16,\n",
        "        \"ppo_epochs\": 4,\n",
        "    }\n",
        "\n",
        "    def __init__(self, policy_model, ref_model, value_model, **ppo_params):\n",
        "        \"\"\"\n",
        "        Initialize PPOTrainer.\n",
        "        Args:\n",
        "            model (torch.model): Hugging Face transformer model with value head\n",
        "            ref_model (torch.model): Hugging Face transformer reference model used for KL penalty\n",
        "            ppo_params (dict or None): PPO parameters for training. Can include following keys:\n",
        "                'lr' (float): Adam learning rate, default: 1.41e-5\n",
        "                'batch_size' (int): Number of samples per optimisation step, default: 256\n",
        "                'forward_batch_size' (int): Number of samples forward passed through model at a time, default: 16\n",
        "                'ppo_epochs' (int): Number of optimisation epochs per batch of samples, default: 4\n",
        "                'gamma' (float)): Gamma parameter for advantage calculation, default: 1.\n",
        "                'lam' (float): Lambda parameter for advantage calcualation, default: 0.95\n",
        "                'cliprange_value' (float): Range for clipping values in loss calculation, default: 0.2\n",
        "                'cliprange' (float): Range for clipping in PPO policy gradient loss, default: 0.2\n",
        "                'vf_coef' (float): Scaling factor for value loss, default: 0.1\n",
        "                'adap_kl_ctrl' (bool): Use adaptive KL control, otherwise linear, default: True\n",
        "                'init_kl_coef' (float): Initial KL penalty coefficient (used for adaptive and linear control), default: 0.2\n",
        "                'target' (float): Target KL value for adaptive KL control, default: 6.0\n",
        "                'horizon' (float): Horizon for adaptive KL control, default: 10000\n",
        "        \"\"\"\n",
        "        self.ppo_params = self.default_params\n",
        "        self.ppo_params.update(ppo_params)\n",
        "\n",
        "        self.ref_model = ref_model\n",
        "        self.policy_model = policy_model\n",
        "        self.value_model = value_model\n",
        "        self.policy_optimizer = Adam(policy_model.parameters(), lr=self.ppo_params['lr'])\n",
        "        self.value_optimizer = Adam(value_model.parameters(), lr=self.ppo_params['lr'])\n",
        "\n",
        "        if self.ppo_params['adap_kl_ctrl']:\n",
        "            self.kl_ctl = AdaptiveKLController(self.ppo_params['init_kl_coef'],\n",
        "                                               self.ppo_params['target'],\n",
        "                                               self.ppo_params['horizon'])\n",
        "        else:\n",
        "            self.kl_ctl = FixedKLController(self.ppo_params['init_kl_coef'])\n",
        "\n",
        "\n",
        "    def step(self, query, response, scores):\n",
        "        \"\"\"\n",
        "        Run a PPO optimisation step.\n",
        "        args:\n",
        "            query (torch.tensor): tensor containing the encoded queries, shape [batch_size, query_length]\n",
        "            response (torch.tensor): tensor containing the encoded responses, shape [batch_size, response_length]\n",
        "            scores (torch.tensor): tensor containing the scores, shape [batch_size]\n",
        "        returns:\n",
        "            train_stats (dict): a summary of the training statistics\n",
        "        \"\"\"\n",
        "\n",
        "        bs = self.ppo_params['batch_size']\n",
        "        timing = dict()\n",
        "        t0 = time.time()\n",
        "\n",
        "        gen_len = response.shape[1]\n",
        "        model_input = torch.cat((query, response), axis=1)\n",
        "\n",
        "        t = time.time()\n",
        "        logprobs, ref_logprobs, values = self.batched_forward_pass(model_input, gen_len)\n",
        "        timing['time/ppo/forward_pass'] = time.time()-t\n",
        "\n",
        "        t = time.time()\n",
        "        rewards, non_score_reward, kl_coef = self.compute_rewards(scores, logprobs, ref_logprobs)\n",
        "        timing['time/ppo/compute_rewards'] = time.time()-t\n",
        "\n",
        "        t = time.time()\n",
        "        all_stats = []\n",
        "        idxs = list(range(bs))\n",
        "        for _ in range(self.ppo_params['ppo_epochs']):\n",
        "            random.shuffle(idxs)\n",
        "            for i in range(bs):\n",
        "                idx = idxs[i]\n",
        "                train_stats = self.train_minibatch(logprobs[idx:idx+1], values[idx:idx+1],\n",
        "                                                   rewards[idx:idx+1],\n",
        "                                                   response[idx:idx+1], model_input[idx:idx+1])\n",
        "                all_stats.append(train_stats)\n",
        "        timing['time/ppo/optimize_step'] = time.time()-t\n",
        "\n",
        "        t = time.time()\n",
        "        train_stats = stack_dicts(all_stats)\n",
        "\n",
        "        # reshape advantages/ratios such that they are not averaged.\n",
        "        train_stats['policy/advantages'] = torch.flatten(train_stats['policy/advantages']).unsqueeze(0)\n",
        "        train_stats['policy/ratio'] = torch.flatten(train_stats['policy/ratio']).unsqueeze(0)\n",
        "\n",
        "        stats = self.record_step_stats(scores=scores, logprobs=logprobs, ref_logprobs=ref_logprobs,\n",
        "                                       non_score_reward=non_score_reward, train_stats=train_stats,\n",
        "                                       kl_coef=kl_coef)\n",
        "        stats = stats_to_np(stats)\n",
        "        timing['time/ppo/calc_stats'] = time.time()-t\n",
        "\n",
        "        self.kl_ctl.update(stats['objective/kl'], self.ppo_params['batch_size'])\n",
        "\n",
        "        timing['time/ppo/total'] = time.time()-t0\n",
        "        stats.update(timing)\n",
        "        return stats\n",
        "\n",
        "    def batched_forward_pass(self, model_input, gen_len):\n",
        "        \"\"\"Calculate model outputs in multiple batches.\"\"\"\n",
        "        bs = self.ppo_params['batch_size']\n",
        "        fbs = self.ppo_params['forward_batch_size']\n",
        "        logprobs = []\n",
        "        ref_logprobs = []\n",
        "        values = []\n",
        "\n",
        "        for i in range(int(self.ppo_params['batch_size']/fbs)):\n",
        "            m_input = model_input[i*fbs:(i+1)*fbs]\n",
        "            logits, _, _ = self.policy_model(m_input)\n",
        "            _, _, v = self.value_model(m_input)\n",
        "            ref_logits, _, _ = self.ref_model(m_input)\n",
        "\n",
        "            values.append(v[:, -gen_len-1:-1].detach())\n",
        "            logprobs.append(logprobs_from_logits(logits[:,:-1,:], m_input[:,1:])[:, -gen_len:].detach())\n",
        "            ref_logprobs.append(logprobs_from_logits(ref_logits[:,:-1,:], m_input[:,1:])[:, -gen_len:].detach())\n",
        "\n",
        "        return torch.cat(logprobs), torch.cat(ref_logprobs), torch.cat(values)\n",
        "\n",
        "    def train_minibatch(self, logprobs, values, rewards, response, model_input):\n",
        "        \"\"\"Train one PPO minibatch\"\"\"\n",
        "        loss_p, train_stats  = self.loss_policy(logprobs, values, rewards, response, model_input)\n",
        "        loss_v = self.loss_value(values, rewards, response, model_input)\n",
        "        self.policy_optimizer.zero_grad()\n",
        "        self.value_optimizer.zero_grad()\n",
        "        loss_p.backward()\n",
        "        loss_v.backward()\n",
        "        self.policy_optimizer.step()\n",
        "        self.value_optimizer.step()\n",
        "        return train_stats\n",
        "\n",
        "    def compute_rewards(self, scores, logprobs, ref_logprobs):\n",
        "        \"\"\"Compute per token rewards from scores and KL-penalty.\"\"\"\n",
        "        kl = logprobs - ref_logprobs\n",
        "        non_score_reward = -self.kl_ctl.value * kl\n",
        "        rewards = non_score_reward.clone().detach()\n",
        "        rewards[:, -1] += scores\n",
        "        return rewards, non_score_reward, self.kl_ctl.value\n",
        "\n",
        "    def loss_value(self, values, rewards, response, model_input):\n",
        "        \"\"\"Calculate value loss\"\"\"\n",
        "        lastgaelam = 0\n",
        "        advantages_reversed = []\n",
        "        gen_len = response.shape[1]\n",
        "\n",
        "        for t in reversed(range(gen_len)):\n",
        "            nextvalues = values[:, t + 1] if t < gen_len - 1 else 0.0\n",
        "            delta = rewards[:, t] + self.ppo_params['gamma'] * nextvalues - values[:, t]\n",
        "            lastgaelam = delta + self.ppo_params['gamma'] * self.ppo_params['lam'] * lastgaelam\n",
        "            advantages_reversed.append(lastgaelam)\n",
        "        advantages = torch.stack(advantages_reversed[::-1]).transpose(0, 1)\n",
        "\n",
        "        returns = advantages + values\n",
        "        advantages = whiten(advantages)\n",
        "        advantages = advantages.detach()\n",
        "\n",
        "        logits, _, _ = self.policy_model(model_input)\n",
        "        _, _, vpred = self.value_model(model_input)\n",
        "\n",
        "        logprob = logprobs_from_logits(logits[:,:-1,:], model_input[:, 1:])\n",
        "\n",
        "        #only the generation part of the values/logprobs is needed\n",
        "        logprob, vpred = logprob[:, -gen_len:], vpred[:,-gen_len-1:-1]\n",
        "\n",
        "        vpredclipped = clip_by_value(vpred,\n",
        "                                     values - self.ppo_params[\"cliprange_value\"],\n",
        "                                     values + self.ppo_params[\"cliprange_value\"])\n",
        "\n",
        "        vf_losses1 = (vpred - returns)**2\n",
        "        vf_losses2 = (vpredclipped - returns)**2\n",
        "        vf_loss = .5 * torch.mean(torch.max(vf_losses1, vf_losses2))\n",
        "\n",
        "        return self.ppo_params['vf_coef'] * vf_loss\n",
        "\n",
        "    def loss_policy(self, old_logprobs, values, rewards, response, model_input):\n",
        "        \"\"\"Calculate policy loss.\"\"\"\n",
        "        lastgaelam = 0\n",
        "        advantages_reversed = []\n",
        "        gen_len = response.shape[1]\n",
        "\n",
        "        for t in reversed(range(gen_len)):\n",
        "            nextvalues = values[:, t + 1] if t < gen_len - 1 else 0.0\n",
        "            delta = rewards[:, t] + self.ppo_params['gamma'] * nextvalues - values[:, t]\n",
        "            lastgaelam = delta + self.ppo_params['gamma'] * self.ppo_params['lam'] * lastgaelam\n",
        "            advantages_reversed.append(lastgaelam)\n",
        "        advantages = torch.stack(advantages_reversed[::-1]).transpose(0, 1)\n",
        "\n",
        "        returns = advantages + values\n",
        "        advantages = whiten(advantages)\n",
        "        advantages = advantages.detach()\n",
        "\n",
        "        logits, _, _ = self.policy_model(model_input)\n",
        "        _, _, vpred = self.value_model(model_input)\n",
        "\n",
        "        logprob = logprobs_from_logits(logits[:,:-1,:], model_input[:, 1:])\n",
        "\n",
        "        #only the generation part of the values/logprobs is needed\n",
        "        logprob, vpred = logprob[:, -gen_len:], vpred[:,-gen_len-1:-1]\n",
        "\n",
        "        vpredclipped = clip_by_value(vpred,\n",
        "                                     values - self.ppo_params[\"cliprange_value\"],\n",
        "                                     values + self.ppo_params[\"cliprange_value\"])\n",
        "\n",
        "        vf_losses1 = (vpred - returns)**2\n",
        "        vf_losses2 = (vpredclipped - returns)**2\n",
        "        vf_loss = .5 * torch.mean(torch.max(vf_losses1, vf_losses2))\n",
        "        vf_clipfrac =  torch.mean(torch.gt(vf_losses2, vf_losses1).double())\n",
        "\n",
        "        ratio = torch.exp(logprob - old_logprobs)\n",
        "\n",
        "        pg_losses = -advantages * ratio\n",
        "        pg_losses2 = -advantages * torch.clamp(ratio,\n",
        "                                               1.0 - self.ppo_params['cliprange'],\n",
        "                                               1.0 + self.ppo_params['cliprange'])\n",
        "\n",
        "        pg_loss = torch.mean(torch.max(pg_losses, pg_losses2))\n",
        "        pg_clipfrac = torch.mean(torch.gt(pg_losses2, pg_losses).double())\n",
        "\n",
        "        entropy = torch.mean(entropy_from_logits(logits))\n",
        "        approxkl = .5 * torch.mean((logprob - old_logprobs)**2)\n",
        "        policykl = torch.mean(logprob - old_logprobs)\n",
        "        return_mean, return_var = torch.mean(returns), torch.var(returns)\n",
        "        value_mean, value_var = torch.mean(values), torch.var(values)\n",
        "\n",
        "        stats = dict(\n",
        "            loss=dict(policy=pg_loss, value=vf_loss),\n",
        "            policy=dict(entropy=entropy, approxkl=approxkl,policykl=policykl, clipfrac=pg_clipfrac,\n",
        "                        advantages=advantages, advantages_mean=torch.mean(advantages), ratio=ratio),\n",
        "            returns=dict(mean=return_mean, var=return_var),\n",
        "            val=dict(vpred=torch.mean(vpred), error=torch.mean((vpred - returns) ** 2),\n",
        "                     clipfrac=vf_clipfrac, mean=value_mean, var=value_var),\n",
        "        )\n",
        "        return pg_loss, flatten_dict(stats)\n",
        "\n",
        "\n",
        "    def record_step_stats(self, kl_coef, **data):\n",
        "        \"\"\"Record training step statistics.\"\"\"\n",
        "        kl = data['logprobs'] - data['ref_logprobs']\n",
        "        mean_kl = torch.mean(torch.sum(kl, axis=-1))\n",
        "        mean_entropy = torch.mean(torch.sum(-data['logprobs'], axis=1))\n",
        "        mean_non_score_reward =torch.mean(torch.sum(data['non_score_reward'], axis=1))\n",
        "        stats = {\n",
        "            'objective/kl': mean_kl,\n",
        "            'objective/kl_dist': kl,\n",
        "            'objective/logprobs': data['logprobs'],\n",
        "            'objective/ref_logprobs': data['ref_logprobs'],\n",
        "            'objective/kl_coef': kl_coef,\n",
        "            'objective/entropy': mean_entropy,\n",
        "            'ppo/mean_non_score_reward': mean_non_score_reward,\n",
        "        }\n",
        "\n",
        "        for k, v in data['train_stats'].items():\n",
        "            stats[f'ppo/{k}'] = torch.mean(v, axis=0)\n",
        "        stats['ppo/val/var_explained'] = 1 - stats['ppo/val/error'] / stats['ppo/returns/var']\n",
        "        return stats"
      ],
      "metadata": {
        "id": "dIla8m6KY2Px"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9K6OuopKOcwc"
      },
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_response_dataset = load_dataset(\"rewardsignal/reddit_writing_prompts\", data_files=\"prompt_responses_full.csv\", split='train[:80%]')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNRynAtbZHsY",
        "outputId": "14b6405d-8e64-466f-c359-e5ba16a901bc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration rewardsignal--reddit_writing_prompts-dd5d2a64487ab606\n",
            "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/rewardsignal--reddit_writing_prompts-dd5d2a64487ab606/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H1xo6-KOcwi"
      },
      "source": [
        "## Load models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miR36jNYOcwj"
      },
      "source": [
        "### Load Reward Model\n",
        "We load a DistilGPT2 classifier fine-tuned on the writing prompt dataset to predict whether a response is the best response (as judged by karma) or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uqqAwnpSOcwj"
      },
      "outputs": [],
      "source": [
        "reward_model = AutoModelForSequenceClassification.from_pretrained(\"anshr/distilgpt2_reward_model_final\")\n",
        "reward_model_tokenizer = AutoTokenizer.from_pretrained(\"anshr/distilgpt2_reward_model_final\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atxMVcRyOcwk"
      },
      "source": [
        "The model outputs are the logits for the not-best and best classes. We will use the logits for the best class as a reward signal for the language model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YZQBaQdOcwl"
      },
      "source": [
        "### Load pre-trained DistilGPT2 language models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YO6Uohs5Ocwl"
      },
      "source": [
        "We load the fine-tuned DistilGPT2 models with a value head and the tokenizer. We load the model three; the first model is optimized while the second model serves as a reference to calculate the KL-divergence from the starting point. This serves as an additional reward signal in the PPO training to make sure the optimized model does not deviate too much from the original language model. The third model allows us to provide value estimates for states - having a separate network from the policy network ensures that updates to the policy network don't reduce value estimate accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "STmOA8z6Ocwl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e5d781d-d571-46e8-86c5-c1b39f2beba4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LMHeadWithValueModel were not initialized from the model checkpoint at anshr/distilgpt2_supervised_model_final and are newly initialized: ['v_head.summary.weight', 'v_head.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of LMHeadWithValueModel were not initialized from the model checkpoint at anshr/distilgpt2_supervised_model_final and are newly initialized: ['v_head.summary.weight', 'v_head.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of LMHeadWithValueModel were not initialized from the model checkpoint at anshr/distilgpt2_supervised_model_final and are newly initialized: ['v_head.summary.weight', 'v_head.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "policy_model = LMHeadWithValueModel.from_pretrained(\"anshr/distilgpt2_supervised_model_final\")\n",
        "policy_model_ref = LMHeadWithValueModel.from_pretrained(\"anshr/distilgpt2_supervised_model_final\")\n",
        "value_model = LMHeadWithValueModel.from_pretrained(\"anshr/distilgpt2_supervised_model_final\")\n",
        "policy_tokenizer = AutoTokenizer.from_pretrained(\"anshr/distilgpt2_supervised_model_final\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ujpd45sOcwm"
      },
      "source": [
        "### Move models to GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb5blwklOcwm"
      },
      "source": [
        "If `cuda` is available move the computations to the GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6A0aeLENOcwm"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "B-69JJ3FOcwm"
      },
      "outputs": [],
      "source": [
        "_ = reward_model.to(device)\n",
        "_ = policy_model.to(device)\n",
        "_ = policy_model_ref.to(device)\n",
        "_ = value_model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set-up for experiment and dataset preparation\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L-ghymKEDK_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"steps\": 25600,\n",
        "    \"batch_size\": 8,\n",
        "    \"forward_batch_size\": 2,\n",
        "    \"ppo_epochs\": 4,   \n",
        "    \"txt_in_len\": 100,\n",
        "    \"txt_out_len\": 200,\n",
        "    \"lr\": 1.41e-5,\n",
        "    \"init_kl_coef\":0.2,\n",
        "    \"target\": 6,\n",
        "    \"horizon\":10000,\n",
        "    \"gamma\":1,\n",
        "    \"lam\":0.95,\n",
        "    \"cliprange\": .2,\n",
        "    \"cliprange_value\":.2,\n",
        "    \"vf_coef\":.1, \n",
        "}"
      ],
      "metadata": {
        "id": "PJB34Tg_SF7c"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_name = 'distilgpt2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, use_fast=False)\n",
        "prompt_prefix = \"Writing Prompt: \"\n",
        "response_prefix = \" Response: \"\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def preprocess_text_function(examples):\n",
        "  examples[\"prompt\"] = [tokenizer.prepare_for_tokenization(prompt.replace('[WP] ', prompt_prefix) + response_prefix)[0] for prompt in examples[\"prompt\"]]\n",
        "  examples[\"prompt_tokens\"] = [tokenizer.encode(prompt, return_tensors='pt', max_length=config['txt_in_len'], padding=\"max_length\").to(device)[0, :config['txt_in_len']] for prompt in examples[\"prompt\"]]\n",
        "  examples[\"decoded_prompt\"] = [tokenizer.decode(token_ids=tokenized_prompt) for tokenized_prompt in examples[\"prompt_tokens\"]]\n",
        "  examples[\"response\"] = [tokenizer.prepare_for_tokenization(response)[0] for response in examples[\"response\"]]\n",
        "  return examples\n",
        "\n",
        "ppo_dataset = prompt_response_dataset.map(preprocess_text_function, batched=True, remove_columns=['Unnamed: 0', 'prompt_id', 'prompt_score', 'prompt_created_utc', 'response_id', 'response_score', 'response_created_utc', 'num_responses', 'response_children', 'score_bin', 'response_rank'])"
      ],
      "metadata": {
        "id": "PnvaDHBYp0sS",
        "outputId": "05968d14-c3a1-41df-96ea-c71cfd38ba4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/rewardsignal--reddit_writing_prompts-dd5d2a64487ab606/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-ec98ef23dbecb1f8.arrow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Function to build batches for reward model from list of texts\n",
        "def build_reward_batch_from_txt(text_list, tokenizer, device):\n",
        "  # tokenize\n",
        "    tensors = [tokenizer.encode(txt, return_tensors=\"pt\").to(device) for txt in text_list]\n",
        "    \n",
        "    # find max length to pad to\n",
        "    max_len = max([t.size()[1] for t in tensors])\n",
        "    \n",
        "    # get padded tensors and attention masks\n",
        "    padded_tensors = []\n",
        "    attention_masks = []\n",
        "    for tensor in tensors:\n",
        "        attention_mask = torch.ones(tensor.size(), device=device)\n",
        "        padded_tensors.append(pad_to_size(tensor, max_len, padding=0))\n",
        "        attention_masks.append(pad_to_size(attention_mask, max_len, padding=0))\n",
        "    \n",
        "    # stack all tensors\n",
        "    padded_tensors = torch.cat(padded_tensors)\n",
        "    attention_masks = torch.cat(attention_masks)  \n",
        "    \n",
        "    return padded_tensors, attention_masks"
      ],
      "metadata": {
        "id": "a-RKOUIDimuy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Io9OtDXIOcwn"
      },
      "source": [
        "## Optimize model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAYIpvs7Ocwn"
      },
      "source": [
        "**Steps**\n",
        "\n",
        "The training loop consists of the following steps:\n",
        "1. Get a batch of queries\n",
        "2. Get the query responses from the policy\n",
        "3. Join query and responses and tokenize for BERT analysis\n",
        "4. Get sentiments for query/responses from BERT\n",
        "5. Optimize policy with PPO using the (query, response, reward) triplet\n",
        "6. Log all the training statistics\n",
        "\n",
        "**Forward batching**\n",
        "\n",
        "Since the models can be fairly big and we want to rollout large PPO batches this can lead to out-of-memory errors when doing the forward passes for text generation and sentiment analysis. We introduce the parameter `forward_batch_size` to split the forward passes into smaller batches. Although this hurts performance a little this is neglectible compared to the computations of the backward passes when optimizing the model. The same parameter is used in the `PPOTrainer` when doing forward passes. The `batch_size` should be a multiple of `forward_batch_size`.\n",
        "\n",
        "**Training time**\n",
        "\n",
        "This step takes **~2h** on a P6000 GPU with the above specified settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cQgypKdaOcwn",
        "outputId": "ed8a1527-8a50-42bb-fd93-3cc6449f6c97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "aee5a8783a444161b1260ad223f0e8cd",
            "7c3d6b784e8f4e2c85c9940b5a85ac24",
            "49ad0f800ec944ada9617181ebc98afe",
            "b58b67a52bbd40e4bb854a5ab4ab5077",
            "88db9aa169a745b7b8f4565b2cd2bb61",
            "a2384341836a434ab1e43f71620553f2",
            "67c65fcdc1af473c8396091070b485b4",
            "589177c506c0486aa2c551b2bdec5278",
            "3fc2f7f717a54642aef75336a8c1d7ac",
            "831fe339537c497aa6c91a9921e61721",
            "f1f5b03cf31e41238893ef9a99d61651"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aee5a8783a444161b1260ad223f0e8cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  import sys\n"
          ]
        }
      ],
      "source": [
        "ppo_trainer = PPOTrainer(policy_model, policy_model_ref, value_model, **config)\n",
        "fbs = config['forward_batch_size']\n",
        "\n",
        "for epoch in tqdm(range(int(np.ceil(config[\"steps\"]/config['batch_size'])))):\n",
        "    torch.cuda.empty_cache()\n",
        "    logs = dict()\n",
        "    game_data = dict()\n",
        "    timing = dict()\n",
        "    t0 = time.time()\n",
        "    \n",
        "    #### get a batch from the dataset\n",
        "    df_batch = ppo_dataset.shuffle().select(range(config[\"batch_size\"]))\n",
        "    game_data['query'] = list(df_batch['decoded_prompt'])\n",
        "    query_tensors = torch.as_tensor(df_batch['prompt_tokens']).to(device)\n",
        "    \n",
        "    #### get response from policy model\n",
        "    t = time.time()\n",
        "    total_length = config['txt_in_len']+config['txt_out_len']\n",
        "    response_tensors = []\n",
        "    for i in range(int(config['batch_size']/fbs)):\n",
        "        response  = respond_to_batch(policy_model, query_tensors[i*fbs:(i+1)*fbs],\n",
        "                                     txt_len=config['txt_out_len'])\n",
        "        response_tensors.append(response)\n",
        "    response_tensors = torch.cat(response_tensors)\n",
        "    game_data['response'] = [policy_tokenizer.decode(response_tensors[i, :]) for i in range(config['batch_size'])]\n",
        "    timing['time/get_response'] = time.time()-t\n",
        "\n",
        "    #### process text for reward model\n",
        "    t = time.time()\n",
        "    texts = [q + r for q,r in zip(game_data['query'], game_data['response'])]\n",
        "    reward_inputs, attention_masks = build_reward_batch_from_txt(texts, reward_model_tokenizer, device)    \n",
        "    timing['time/build_input_sentiment'] = time.time()-t\n",
        "\n",
        "    #### get rewards\n",
        "    t = time.time()\n",
        "    rewards = []\n",
        "    for i in range(int(config['batch_size']/fbs)):\n",
        "        res = reward_model.forward(input_ids=reward_inputs[i*fbs:(i+1)*fbs],\n",
        "                                      attention_mask=attention_masks[i*fbs:(i+1)*fbs])[0][:, 1].detach()\n",
        "        rewards.append(res)\n",
        "    rewards = torch.cat(rewards)\n",
        "    timing['time/get_sentiment_preds'] = time.time()-t\n",
        "    \n",
        "    #### Run PPO training \n",
        "    t = time.time()\n",
        "    stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n",
        "    timing['time/optimization'] = time.time()-t\n",
        "     \n",
        "    #### Log everything\n",
        "    timing['time/epoch'] = time.time()-t0\n",
        "    table_rows = [list(r) for r in zip(game_data['query'], game_data['response'], rewards.cpu().tolist())]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLoPS8sjOcwo"
      },
      "source": [
        "## Model inspection\n",
        "Let's inspect some examples from the dataset. We can use `policy_model_ref` to compare the tuned model `policy_model` against the model before optimisation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zKHoyWaqOcwo",
        "outputId": "fbb7d719-cc82-49b3-93f8-0ae1acb5b23f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/csv/rewardsignal--reddit_writing_prompts-dd5d2a64487ab606/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-967e17cac2a4508e.arrow\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               query  \\\n",
              "0  Writing Prompt: When someone's heart breaks so...   \n",
              "1  Writing Prompt: At 18 years of age, everyone g...   \n",
              "2  Writing Prompt: You are the bane of anime hero...   \n",
              "3  Writing Prompt: The demon you conjured up 20 y...   \n",
              "\n",
              "                                   response (before)  \\\n",
              "0  When my wife and your name is no longer necess...   \n",
              "1  \"Come 1 minute ago\\n\\nHave you found increasin...   \n",
              "2  What it's about to take a look at this story\\n...   \n",
              "3  The dust has failed me, another!\\n\\nThe here i...   \n",
              "\n",
              "                                    response (after)  rewards (before)  \\\n",
              "0  All TD History Convert instructions will fail ...         -0.432349   \n",
              "1  AuthorPreview: millennial idk on your knee?\\n\\...          0.621766   \n",
              "2  's bugs grow louder and the beautiful toddler ...         -0.048603   \n",
              "3  bottom-famyan drawback 2 minutes late!\\nThe le...          0.144893   \n",
              "\n",
              "   rewards (after)  \n",
              "0         1.045356  \n",
              "1         0.995689  \n",
              "2         1.388714  \n",
              "3        -1.311743  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-94866ee0-0f7a-4c4a-bbd6-1e07d65bf0e3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>response (before)</th>\n",
              "      <th>response (after)</th>\n",
              "      <th>rewards (before)</th>\n",
              "      <th>rewards (after)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Writing Prompt: When someone's heart breaks so...</td>\n",
              "      <td>When my wife and your name is no longer necess...</td>\n",
              "      <td>All TD History Convert instructions will fail ...</td>\n",
              "      <td>-0.432349</td>\n",
              "      <td>1.045356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Writing Prompt: At 18 years of age, everyone g...</td>\n",
              "      <td>\"Come 1 minute ago\\n\\nHave you found increasin...</td>\n",
              "      <td>AuthorPreview: millennial idk on your knee?\\n\\...</td>\n",
              "      <td>0.621766</td>\n",
              "      <td>0.995689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Writing Prompt: You are the bane of anime hero...</td>\n",
              "      <td>What it's about to take a look at this story\\n...</td>\n",
              "      <td>'s bugs grow louder and the beautiful toddler ...</td>\n",
              "      <td>-0.048603</td>\n",
              "      <td>1.388714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Writing Prompt: The demon you conjured up 20 y...</td>\n",
              "      <td>The dust has failed me, another!\\n\\nThe here i...</td>\n",
              "      <td>bottom-famyan drawback 2 minutes late!\\nThe le...</td>\n",
              "      <td>0.144893</td>\n",
              "      <td>-1.311743</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94866ee0-0f7a-4c4a-bbd6-1e07d65bf0e3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-94866ee0-0f7a-4c4a-bbd6-1e07d65bf0e3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-94866ee0-0f7a-4c4a-bbd6-1e07d65bf0e3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "#### get a batch from the dataset\n",
        "bs = 4\n",
        "game_data = dict()\n",
        "df_batch = ppo_dataset.shuffle(seed=40).select(range(bs))\n",
        "game_data['query'] = list(df_batch['decoded_prompt'])\n",
        "query_tensors = torch.as_tensor(df_batch['prompt_tokens']).to(device)\n",
        "\n",
        "#### get response from gpt2 and gpt2_ref\n",
        "total_length = config['txt_in_len']+config['txt_out_len']\n",
        "response_tensors_ref  = respond_to_batch(policy_model_ref, query_tensors, txt_len=config['txt_out_len'])\n",
        "game_data['response (before)'] = [policy_tokenizer.decode(response_tensors_ref[i, :]) for i in range(bs)]\n",
        "\n",
        "response_tensors  = respond_to_batch(policy_model, query_tensors, txt_len=config['txt_out_len'])\n",
        "game_data['response (after)'] = [policy_tokenizer.decode(response_tensors[i, :]) for i in range(bs)]\n",
        "\n",
        "#### sentiment analysis of query/response pairs before/after\n",
        "texts = [q + r for q,r in zip(game_data['query'], game_data['response (before)'])]\n",
        "reward_inputs, attention_masks = build_reward_batch_from_txt(texts, reward_model_tokenizer, device)    \n",
        "rewards = reward_model.forward(input_ids=reward_inputs, attention_mask=attention_masks)[0][:, 1].detach()\n",
        "game_data['rewards (before)'] = rewards.cpu().numpy()\n",
        "\n",
        "texts = [q + r for q,r in zip(game_data['query'], game_data['response (after)'])]\n",
        "reward_inputs, attention_masks = build_reward_batch_from_txt(texts, reward_model_tokenizer, device)    \n",
        "rewards = reward_model.forward(input_ids=reward_inputs, attention_mask=attention_masks)[0][:, 1].detach()\n",
        "game_data['rewards (after)'] = rewards.cpu().numpy()\n",
        "\n",
        "# store results in a dataframe\n",
        "df_results = pd.DataFrame(game_data)\n",
        "df_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wk4tHlPKOcwp"
      },
      "source": [
        "Looking at the reward mean/median of the generated sequences we observe a significant difference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "40oKYlbeOcwp",
        "outputId": "b79e2a0f-51d1-49b0-bf62-7add3873f419",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "rewards (before)    0.071427\n",
              "rewards (after)     0.529504\n",
              "dtype: float32"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "median:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "rewards (before)    0.048145\n",
              "rewards (after)     1.020523\n",
              "dtype: float32"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "print('mean:')\n",
        "display(df_results.mean())\n",
        "print()\n",
        "print('median:')\n",
        "display(df_results.median())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(df_results)):\n",
        "  print(\"Prompt #\" + str(i+1) + \"\\n\" + df_results[\"query\"][i])\n",
        "  print(\"Reference Response #\" + str(i+1) + \"\\n\" + df_results[\"response (before)\"][i])\n",
        "  print(\"Trained Response #\" + str(i+1) + \"\\n\" +df_results[\"response (after)\"][i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuYtU7paaa4t",
        "outputId": "0723a2ec-693c-4e1d-fa4d-c90c79be43e6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt #1\n",
            "Writing Prompt: When someone's heart breaks so does a piece of our world; this creates fissures, valleys, and even cracks in the pavement. Tell me the story behind the Grand Canyon. Response: <|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
            "Reference Response #1\n",
            "When my wife and your name is no longer necessary. If one would at least watch until you get out of bed, your gun is now on your way back.\n",
            "\n",
            "The formulas you see would probably happen automatically when high scoring cleanses were requested. The task of taking ownership of a weekend's meal helps to determine the origin of what's in myWriting Prompt: *Please select type of sign phrase for friend where per minute, you must immediately leave a note in the archive with \"Decided to remain strolled in\" on your computer.\n",
            "\n",
            "Bicycle soon wears off*\n",
            "\n",
            "There may be no time to continue on track this operation. Also, please *please read This*\n",
            "\n",
            "Serial List of Parts No Reminders\n",
            "\n",
            "Conversions to keep temporal data shows you wont whip up poisons with a materials bucket like a broom and some junk games\n",
            "\n",
            "You\n",
            "\n",
            "Name in Week 1\n",
            "\n",
            "(note week 3: Glitching Dreams - 2 of you lay naked and\n",
            "Trained Response #1\n",
            "All TD History Convert instructions will fail my first thought everyone gets what most people like a letter where the entire cryptic message can be found on another's head.\n",
            "\n",
            "The next information you can delete this archive with your return card\n",
            "\n",
            "Dragons for studying. You always got the message that your next mistake needs to be sorted. Click here *starts in stock:\"Hello everyone! Seriously, dont forget to put it at ease...everything really matters. Captain Chemistry recipe QR code:\n",
            "\n",
            "\n",
            " ++++++++\n",
            "\n",
            "I woke up to a dull feeling when I left my last name (they got it)\n",
            "\n",
            "\"My friend, this isn't great!\" Came his heart pumping hot. He thought the fight with her with a shatterproof, but it was okay to tell me that he and I wouldn't get it when you won't have one replacement. It turns out medical marijuana is under your immediate best interests.\n",
            "\n",
            "\"You are going to die this week of the dead\n",
            "Prompt #2\n",
            "Writing Prompt: At 18 years of age, everyone gets a weapon based on their personality and strengths. All your friends got traditional weaponry, but you...oh, you got something interesting that no one knows how to wield. Response: <|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
            "Reference Response #2\n",
            "\"Come 1 minute ago\n",
            "\n",
            "Have you found increasing energy error messages to your classification\n",
            "\n",
            "Any number of possibilities are coming to an end\n",
            "\n",
            "Generate recycleable on a server file at any minute\n",
            "\n",
            "hot key: <<800:150 (and it's already 4:18 pm today.)\n",
            "\n",
            "\n",
            "OPERATIONS NEED to learn more of new ways we can gain access to your karma, and you're getting it\n",
            "\n",
            "A scout team in grave danger in North American superwarriors make a few things clear :)\n",
            "\n",
            "Your friend's dog got a very scripted message. 2\" clicks like bullets, helpful for taking care of matters beyond his fingers. You have no idea where that is or why should i give you this handy tea, it has to be easy. You've got to start a list of 1bowling heartbeat endings, and ask to take care of your beer.\n",
            "\n",
            "You'll rest TODAY!\n",
            "\n",
            "Shit.\n",
            "\n",
            "I'm sorry if I'm struggling\n",
            "Trained Response #2\n",
            "AuthorPreview: millennial idk on your knee?\n",
            "\n",
            "After seven years of war\n",
            "\n",
            "\n",
            "Are you sure you couldn't have achieved this, we can certainly add to it once again.\n",
            "\n",
            "You should check across your favorite URL for all when your neutroids are still attached to your left hand cradles. \n",
            "\n",
            "With an testosterone drug to keep you on your feet for furlough I highly recommend your fee for veterans to live in nearby restaurants. \n",
            "\n",
            "I am sick. So you have done it. You probably want to be happy.\n",
            "\n",
            "\n",
            "\n",
            "If you haven't heard anything in about this world to make me stop binging this is a long time in time\n",
            "\n",
            "*Now you're not going to want to hurt anymore...*\n",
            "\n",
            "Two minutes pass, I've written this guide you see, but I was annoyed when I prompted those of you.\n",
            "\n",
            "\n",
            "\n",
            "---\n",
            "It was a pretty big time for them in this day\n",
            "\n",
            "F\n",
            "Prompt #3\n",
            "Writing Prompt: You are the bane of anime heroes everywhere. How? You don't shout out the names and explanations of each attack Response: <|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
            "Reference Response #3\n",
            "What it's about to take a look at this story\n",
            "\n",
            "The bargain.\n",
            "\n",
            "\n",
            "\n",
            "When someone earns XP, instead of wasting your memories needed it extra fuel. We delayed sale of borrowed images technology developed to potentially advance the millenia of RAM. We've given each other a new video for the average redone! We may well win some odd games with a sexy number of areas your schizophrenia took. Avoiding the feeders, eye patch over squeezed emotions, leftovers are welcome with as little boos later....\n",
            "\n",
            "It took days for everyone to plug the manual you find it could still be of no use, but feel free to just shrug that once, you are done with...\n",
            "\n",
            "(1:37 am)\n",
            "\n",
            "*One man in blue seems to be found and kidnapped! KILL THE ARROW TO THE LAST OF DREAMS\n",
            "\n",
            "[WP]Big news next: Great craftsmanship brands -BRIT, bacon, milk, bacon, jelly sandwich\n",
            "Trained Response #3\n",
            "'s bugs grow louder and the beautiful toddler was with no hassle of the rest of your life. It takes a couple of hours for me\n",
            "\n",
            "For those of you who think you didn't know this\n",
            "\n",
            "This is not good for you 71 minutes ago\n",
            "\n",
            "\n",
            "They said you got some idealistic lighting and water repeaters. This is the first time I've seen this daily...I just got to pee.\n",
            "\n",
            "Thank you to the debate where your company has you, all that you and everyone else in the huddle of the universe have given to leave you the codes\n",
            "\n",
            "Basically, a woman ending the life\n",
            "\n",
            "I didn't know the full stories when I saw him activating\n",
            "\n",
            "It requires posting any information you get for each letter you want. So please read again...\n",
            "\n",
            "NOVA: I'll pull this out of a cave door well well after a minute \n",
            "\n",
            "I didn't know, but every 5 minutes they found the second section of their fleet is in\n",
            "Prompt #4\n",
            "Writing Prompt: The demon you conjured up 20 years ago is at your front door. She says that her and Lucifer got in a fight and she needs a place to stay for awhile. Response: <|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
            "Reference Response #4\n",
            "The dust has failed me, another!\n",
            "\n",
            "The here is a mental health lawsuit.Emotion to you suddenly get this pretty easy and not life saving the day. This was it however, was won!\n",
            "\n",
            "11:17am\n",
            "\n",
            "A poster has surfaced via \n",
            "\n",
            "\n",
            "\n",
            "\\-----------\n",
            "\n",
            "\n",
            "Anyways, go check out the lineup of treats and tools you need to know to stop your serious daughter\n",
            "\n",
            "You nevermind and lose it.\n",
            "\n",
            "\"Shit.\" repeated Carol Gates, one mile from me\n",
            "\n",
            "I saw a reporter at hundreds of pairs of hands tightened their shoulders, crafted the human body easier for the next 10 minutes while holding their breath.\n",
            "\n",
            "U. Hulk\n",
            "\n",
            "I wasn't about to protest!\n",
            "\n",
            "WE ARE ABUSE OF ACCOUNTED\n",
            "\n",
            "&# begin streaming pirating\n",
            "\n",
            "Today is the last few days of retroactive to release link to file attachments most necessary\n",
            "\n",
            "The traveler train enters view re: what\n",
            "Trained Response #4\n",
            "bottom-famyan drawback 2 minutes late!\n",
            "The leader behind these lists are the current updates\n",
            "\n",
            "&#\n",
            "\n",
            "This is my third time telling me about some of the emerging traits that make, life of gods and fallen angels. You are not welcome\n",
            "\n",
            "Ignoring the toothfalls people use to grow hinds of the oppressors who are annoying them to you around everyday. A simple test, all you are seeing is passersmeters and the stars best to her.\n",
            "\n",
            "You shall fail.\n",
            "\n",
            "\n",
            "It's a must be pragmatic move. There is a lot of time, I've maybe some Ted Hayes and I teamed up again for the LiveJournal just a couple of days ago.\n",
            "\n",
            "This mission statement.\n",
            "\n",
            "First time posting.\n",
            "\n",
            "I see what you are thinking is my favorite way to take a turn coming this weekend, my name is Maurice Goodwin.\n",
            "\n",
            "Ok, I need some extra provocation.\n",
            "\n",
            "The first generation of humans, not needing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQNK6C5DOcwp"
      },
      "source": [
        "## Save model\n",
        "We upload the model to the huggingface hub for later usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "toahL9oeOcwp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230,
          "referenced_widgets": [
            "851f47f5294c48bc8590be4fb5bbd67b",
            "19412059dc8d4b67aa1ae63fdbe0eda3",
            "1012c223d0dd439bbcec666b78fe9216",
            "598e0f052f3e4d69a1a97e7d38008258",
            "7abe6484524748c0a6f2dc3ededebf57",
            "49fee9805451412885e649aa906bc517",
            "14248b3906bf4df2af8fda0dc56040f2",
            "f64ce3406456408899905cbdb896a993",
            "6fd54d22a82f490a8bb2e6a65ff0e6be",
            "452aa24c83b34b9089eab78d937fb5a9",
            "7447df5640c24280b6d4075da9a0ba06"
          ]
        },
        "outputId": "4c8d55f2-4cb0-4a70-d816-6d6a7704a94f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/huggingface_hub/utils/_deprecation.py:43: FutureWarning: Pass token='distilgpt2_trained_policy_model_final' as keyword args. From version 0.7 passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/huggingface_hub/hf_api.py:599: FutureWarning: `create_repo` now takes `token` as an optional positional argument. Be sure to adapt your code!\n",
            "  FutureWarning,\n",
            "Cloning https://huggingface.co/anshr/distilgpt2_trained_policy_model_final into local empty directory.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Upload file pytorch_model.bin:   0%|          | 3.34k/319M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "851f47f5294c48bc8590be4fb5bbd67b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "To https://huggingface.co/anshr/distilgpt2_trained_policy_model_final\n",
            "   78d7142..7690790  main -> main\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://huggingface.co/anshr/distilgpt2_trained_policy_model_final/commit/7690790ae909520c96517181708099a9375b0bf2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "policy_model.push_to_hub(tokenizer_name + \"_trained_policy_model_final\", use_temp_dir=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results and Discussion\n",
        "Overall results are pretty mixed to negative. We do seem to have optimized against a (suboptimal) reward signal, but this is very plasuibly just sampling error. The differences between the two models (the reference and the trained policy model) don't seem to really be \"better\" as far as writing quality, at least to the human eye- both seem to be wildly off-topic and incoherent.\n",
        "\n",
        "Perhaps with some repeated iterations of optimizing the reward model with human labels of policy outputs and then optimization of the policy model again, we might get outputs that are \"better\" in some subjective measure of writing quality. I was also bottle-necked on compute, limiting batch and text input/output size, as well as model size, so it's possible that purely with more compute we'd get more promising results."
      ],
      "metadata": {
        "id": "v6hHUIg27_28"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "name": "03-writing-prompts-rlhf.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "background_execution": "on"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cd76ed84e13f4f1196a4c49fc92505ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ddb8794cae0d4d57ba70ee94ad8b2e69",
              "IPY_MODEL_6994bd4bfc4d4225a146e03bd9636912",
              "IPY_MODEL_a38c9d3580f6483cb8c1511a50cda803",
              "IPY_MODEL_68046152fe0d45fe86b5155aaac59a5e",
              "IPY_MODEL_4f585770b6c44dafb61676cf62d6e067"
            ],
            "layout": "IPY_MODEL_ed719c66f4c140b5889a07d045b66e19"
          }
        },
        "ddb8794cae0d4d57ba70ee94ad8b2e69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db8854d65a0b409d930ea4f3742005ba",
            "placeholder": "",
            "style": "IPY_MODEL_9bfd7482e525464783234f1899a85b71",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "6994bd4bfc4d4225a146e03bd9636912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_b848bc78623a4fde999de5ce192cc9ea",
            "placeholder": "",
            "style": "IPY_MODEL_3d79cfe9ad2b45909d7cfc9bf1a3ff4a",
            "value": ""
          }
        },
        "a38c9d3580f6483cb8c1511a50cda803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_55d2ab452e6e4d3ab78fad0cf7e5317b",
            "style": "IPY_MODEL_29f51c36ad534125b9121f4cd48f724e",
            "tooltip": ""
          }
        },
        "68046152fe0d45fe86b5155aaac59a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1155bee42134434a93ea29b88e1f353d",
            "placeholder": "",
            "style": "IPY_MODEL_ef55295181734966a3771b075b21153a",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. <br> <i>Logging in with your username and password is deprecated and\nwon't be possible anymore in the near future. You can still use them for now by\nclicking below.</i> </center>"
          }
        },
        "4f585770b6c44dafb61676cf62d6e067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Use password",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_9a82c8ab3da9488e9e2376ed7f7c6c76",
            "style": "IPY_MODEL_750469af67ff4c43b5a4f8565a4715dd",
            "tooltip": ""
          }
        },
        "ed719c66f4c140b5889a07d045b66e19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "db8854d65a0b409d930ea4f3742005ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bfd7482e525464783234f1899a85b71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b848bc78623a4fde999de5ce192cc9ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d79cfe9ad2b45909d7cfc9bf1a3ff4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55d2ab452e6e4d3ab78fad0cf7e5317b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29f51c36ad534125b9121f4cd48f724e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "1155bee42134434a93ea29b88e1f353d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef55295181734966a3771b075b21153a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a82c8ab3da9488e9e2376ed7f7c6c76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "750469af67ff4c43b5a4f8565a4715dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "aee5a8783a444161b1260ad223f0e8cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c3d6b784e8f4e2c85c9940b5a85ac24",
              "IPY_MODEL_49ad0f800ec944ada9617181ebc98afe",
              "IPY_MODEL_b58b67a52bbd40e4bb854a5ab4ab5077"
            ],
            "layout": "IPY_MODEL_88db9aa169a745b7b8f4565b2cd2bb61"
          }
        },
        "7c3d6b784e8f4e2c85c9940b5a85ac24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2384341836a434ab1e43f71620553f2",
            "placeholder": "",
            "style": "IPY_MODEL_67c65fcdc1af473c8396091070b485b4",
            "value": "100%"
          }
        },
        "49ad0f800ec944ada9617181ebc98afe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_589177c506c0486aa2c551b2bdec5278",
            "max": 3200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3fc2f7f717a54642aef75336a8c1d7ac",
            "value": 3200
          }
        },
        "b58b67a52bbd40e4bb854a5ab4ab5077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_831fe339537c497aa6c91a9921e61721",
            "placeholder": "",
            "style": "IPY_MODEL_f1f5b03cf31e41238893ef9a99d61651",
            "value": " 3200/3200 [16:09:06&lt;00:00, 18.21s/it]"
          }
        },
        "88db9aa169a745b7b8f4565b2cd2bb61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2384341836a434ab1e43f71620553f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67c65fcdc1af473c8396091070b485b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "589177c506c0486aa2c551b2bdec5278": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fc2f7f717a54642aef75336a8c1d7ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "831fe339537c497aa6c91a9921e61721": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1f5b03cf31e41238893ef9a99d61651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "851f47f5294c48bc8590be4fb5bbd67b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19412059dc8d4b67aa1ae63fdbe0eda3",
              "IPY_MODEL_1012c223d0dd439bbcec666b78fe9216",
              "IPY_MODEL_598e0f052f3e4d69a1a97e7d38008258"
            ],
            "layout": "IPY_MODEL_7abe6484524748c0a6f2dc3ededebf57"
          }
        },
        "19412059dc8d4b67aa1ae63fdbe0eda3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49fee9805451412885e649aa906bc517",
            "placeholder": "",
            "style": "IPY_MODEL_14248b3906bf4df2af8fda0dc56040f2",
            "value": "Upload file pytorch_model.bin: 100%"
          }
        },
        "1012c223d0dd439bbcec666b78fe9216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f64ce3406456408899905cbdb896a993",
            "max": 333972887,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6fd54d22a82f490a8bb2e6a65ff0e6be",
            "value": 333972887
          }
        },
        "598e0f052f3e4d69a1a97e7d38008258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_452aa24c83b34b9089eab78d937fb5a9",
            "placeholder": "",
            "style": "IPY_MODEL_7447df5640c24280b6d4075da9a0ba06",
            "value": " 319M/319M [04:36&lt;00:00, 790kB/s]"
          }
        },
        "7abe6484524748c0a6f2dc3ededebf57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49fee9805451412885e649aa906bc517": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14248b3906bf4df2af8fda0dc56040f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f64ce3406456408899905cbdb896a993": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fd54d22a82f490a8bb2e6a65ff0e6be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "452aa24c83b34b9089eab78d937fb5a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7447df5640c24280b6d4075da9a0ba06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}